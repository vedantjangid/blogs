<html>

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="/images/favicon.svg">
    
    <link rel="stylesheet" href="/scss/global.min.efdec19a841df5aaebee3bb759088658a1ec421db02f87f11b06c62ee87d7064.css">
    
    <link rel="stylesheet" href="/css/prism.css" />
    <link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel="stylesheet">
    <script type="module">
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
      mermaid.initialize({ startOnLoad: true });
    </script>
    

 






	




<title>From GCS to BigQuery: Building Scalable ETL Pipelines with Apache Airflow üßë‚Äçüíª | Vedant Writes</title>
<meta name="description" content="
Want to move data from Google Cloud Storage to BigQuery, transform it, and make it analyst-friendly‚Äîall in a single, reliable pipeline? Here&rsquo;s how I did it with Airflow, and how you can too.

üëã Why This Pipeline?
Let&rsquo;s be honest: data engineering isn&rsquo;t just about crunching numbers. It&rsquo;s about making sure the right data lands in the right place, in the right shape, every single time‚Äîeven when the world throws you curveballs.">
<meta property="og:title" content="From GCS to BigQuery: Building Scalable ETL Pipelines with Apache Airflow üßë‚Äçüíª | Vedant Writes">
<meta property="og:site_name" content="Vedant Writes">
<meta property="og:description" content="
Want to move data from Google Cloud Storage to BigQuery, transform it, and make it analyst-friendly‚Äîall in a single, reliable pipeline? Here&rsquo;s how I did it with Airflow, and how you can too.

üëã Why This Pipeline?
Let&rsquo;s be honest: data engineering isn&rsquo;t just about crunching numbers. It&rsquo;s about making sure the right data lands in the right place, in the right shape, every single time‚Äîeven when the world throws you curveballs.">
<meta property="og:url" content="http://localhost:1313/post/from-gcs-to-bigquery-airflow-etl/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:image" content='http://localhost:1313/images/airflow-gcs-bq.png'><meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="From GCS to BigQuery: Building Scalable ETL Pipelines with Apache Airflow üßë‚Äçüíª | Vedant Writes">

	<link rel="canonical" href="http://localhost:1313/post/from-gcs-to-bigquery-airflow-etl/">


	<meta name="twitter:description" content="
Want to move data from Google Cloud Storage to BigQuery, transform it, and make it analyst-friendly‚Äîall in a single, reliable pipeline? Here&rsquo;s how I did it with Airflow, and how you can too.

üëã Why This Pipeline?
Let&rsquo;s be honest: data engineering isn&rsquo;t just about crunching numbers. It&rsquo;s about making sure the right data lands in the right place, in the right shape, every single time‚Äîeven when the world throws you curveballs.">
<meta name="twitter:image" content="http://localhost:1313/images/airflow-gcs-bq.png">
<meta property="article:published_time" content="2025-06-27T00:00:00&#43;00:00">
	<meta property="article:updated_time" content="2025-06-27T00:00:00&#43;00:00">



    </head>


<body class="line-numbers">

    
    <script src="/js/initColors.js"></script>

    <div class="layout-styled">

        <Section class="section">
  <div class="nav-container">
    <a class="logo-link" href="/">
      <!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="vedant writes blog" content="width=device-width, initial-scale=1.0">

  <title>Vedant Writes</title>
  <style>
    h2 {
      font-size: 2rem;
       
      margin: 0;
      line-height: 1.2;
      display: inline-flex;
      align-items: center;
    }

    .logo-bold {
      font-weight: 700;
       

       
    }

    .logo-thin {
      font-weight: 300;
       
      color: #666;
       
      margin-left: 4px;
       
    }



     
    @media (max-width: 768px) {
      #logo-desktop {
        display: none;
      }

      #logo-mobile {
        display: block;
      }
    }
  </style>
</head>

<body>
  <div id="logo-desktop">
    <h2>
      <span class="logo-bold">vedant</span>
      <span class="logo-thin">writes</span>
    </h2>
  </div>
  <div id="logo-mobile" class="hidden">
    <h2>
      <span class="logo-bold">vedant</span>
      <span class="logo-thin">writes</span>
    </h2>
  </div>
</body>

</html>
      <span class="header-hidden">Navigate back to the homepage</span>
    </a>
    <div class="nav-controls">
      <button id="copyButton" class="icon-wrapper">
        <svg
    class="icon-image"
    width="24"
    height="20"
    viewBox="0 0 24 20"
    fill="none"
    xmlns="http://www.w3.org/2000/svg"
    >
    <path
      fillRule="evenodd"
      clipRule="evenodd"
      d="M2 5C2 3.34328 3.34328 2 5 2H14C15.6567 2 17 3.34328 17 5V9C17 10.6567 15.6567 12 14 12H10C9.44771 12 9 12.4477 9 13C9 13.5523 9.44771 14 10 14H14C16.7613 14 19 11.7613 19 9V5C19 2.23872 16.7613 0 14 0H5C2.23872 0 0 2.23872 0 5V9C0 10.4938 0.656313 11.8361 1.6935 12.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625C3.47028 12.2483 3.43068 11.6164 3.0165 11.2511C2.39169 10.6999 2 9.89621 2 9V5ZM7 11C7 9.34328 8.34328 8 10 8H14C14.5523 8 15 7.55228 15 7C15 6.44772 14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11V15C5 17.7613 7.23872 20 10 20H19C21.7613 20 24 17.7613 24 15V11C24 9.50621 23.3437 8.16393 22.3065 7.24906C21.8923 6.88372 21.2604 6.92332 20.8951 7.3375C20.5297 7.75168 20.5693 8.38361 20.9835 8.74894C21.6083 9.30007 22 10.1038 22 11V15C22 16.6567 20.6567 18 19 18H10C8.34328 18 7 16.6567 7 15V11Z"
      fill="#000"
    />
</svg>
        <div id="toolTip" class="tool-tip " >
            copied
        </div>
        <input id="copyText" style="opacity: 0;" type="text" class="tool-tip " />
      </button>

      <button id="themeColorButton" class="icon-wrapper"> 
        <div id="sunRays" class="sun-rays"></div>
        <div id="moonOrSun" class="moon-or-sun"></div>
        <div id="moonMask" class="moon-mask"></div>
      </button>
    </div>
</div>
</Section>


<script src="/js/toggleLogos.js"></script>


<script src="/js/toggleColors.js"></script>


<script src="/js/copyUrl.js"></script>

        

<section class="section narrow">

    <section id="articleHero" class="section narrow">
    <div class="article-hero">
        <header class="article-header">
            <h1 class="article-hero-heading">From GCS to BigQuery: Building Scalable ETL Pipelines with Apache Airflow üßë‚Äçüíª</h1>
            <div class="article-hero-subtitle">
                <div class="article-meta">
                    


    
            <a href="/authors/vedant/" class="article-author-link">
                
                    <div class="article-author-avatar">
                        <img src="/images/vedant-jangid.png" />
                    </div>
                
                
                <strong>Vedant</strong>
                
                <span class="hide-on-mobile">,&nbsp;</span>
            </a>
    



<script src="/js/collapseAuthors.js"></script>
                    June 27, 2025
                    ‚Ä¢ 7 min read
                </div>
            </div>
        </header>
        
        <div class="article-hero-image" id="ArticleImage__Hero">
            <img src="/images/airflow-gcs-bq.png">
        </div>
        
    </div>
</section>


    <aside id="progressBar" class="aside-container">
    <div class="aside-align">
      <div>
        <div class="overlap-container">
        </div>
      </div>
    </div>

    <div class="progress-container" tabIndex={-1}>
        <div class="track-line" aria-hidden="true">
            <div id="progressIndicator" class="progress-line"></div>
        </div>
    </div>
</aside>


    <article  id="articleContent" class="post-content" style="position:relative;">
        <h1></h1>
<p>Want to move data from Google Cloud Storage to BigQuery, transform it, and make it analyst-friendly‚Äîall in a single, reliable pipeline? Here&rsquo;s how I did it with Airflow, and how you can too.</p>
<hr>
<h2 id="-why-this-pipeline">üëã Why This Pipeline?</h2>
<p>Let&rsquo;s be honest: data engineering isn&rsquo;t just about crunching numbers. It&rsquo;s about making sure the right data lands in the right place, in the right shape, every single time‚Äîeven when the world throws you curveballs.</p>
<p>I recently built a pipeline to load global health data from GCS into BigQuery, split it by country, and create clean reporting views. Here&rsquo;s the architecture that made it all work (and saved me from 3 AM alerts):</p>
<hr>
<h2 id="-how-it-all-fits-together">üèóÔ∏è How It All Fits Together</h2>
<div class="mermaid">

graph TD
    A[GCS Bucket] -->|CSV File| B[File Existence Check]
    B --> C[Load to BigQuery Staging]
    C --> D[Create Country Tables]
    D --> E[Create Reporting Views]
    E --> F[Success Notification]
    subgraph "BigQuery Datasets"
        G[staging_dataset]
        H[transform_dataset] 
        I[reporting_dataset]
    end
    C --> G
    D --> H
    E --> I

</div> 
<hr>
<h2 id="-tools--stack">üß∞ Tools &amp; Stack</h2>
<ul>
<li><strong>Apache Airflow</strong> ü™Å</li>
<li><strong>Google Cloud Storage</strong> ‚òÅÔ∏è</li>
<li><strong>BigQuery</strong> üè¢</li>
<li><strong>Python</strong> üêç</li>
</ul>
<hr>
<h2 id="-the-real-world-challenge">üéØ The Real-World Challenge</h2>
<p>Picture this:</p>
<blockquote>
<p>You&rsquo;ve got a CSV of global health data in GCS. Your mission:</p>
<ul>
<li>Load it into BigQuery for analysis</li>
<li>Create country-specific tables for regional teams</li>
<li>Generate reporting views with clean, analyst-friendly columns</li>
<li>Handle failures gracefully and keep tabs on the whole process</li>
</ul></blockquote>
<p>Sound familiar? Here&rsquo;s how I tackled it.</p>
<hr>
<h2 id="-the-solution-a-multi-stage-etl-dag">üí° The Solution: A Multi-Stage ETL DAG</h2>
<p><em>This isn&rsquo;t just a DAG‚Äîit&rsquo;s a battle-tested blueprint for scalable, maintainable data pipelines.</em></p>
<hr>
<h2 id="-the-complete-dag-implementation">üìù The Complete DAG Implementation</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> datetime <span style="color:#f92672">import</span> datetime
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> airflow <span style="color:#f92672">import</span> DAG
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> airflow.providers.google.cloud.sensors.gcs <span style="color:#f92672">import</span> GCSObjectExistenceSensor
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> airflow.providers.google.cloud.transfers.gcs_to_bigquery <span style="color:#f92672">import</span> GCSToBigQueryOperator
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> airflow.providers.google.cloud.operators.bigquery <span style="color:#f92672">import</span> BigQueryInsertJobOperator
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> airflow.operators.dummy_operator <span style="color:#f92672">import</span> DummyOperator
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># DAG default arguments</span>
</span></span><span style="display:flex;"><span>default_args <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;owner&#39;</span>: <span style="color:#e6db74">&#39;airflow&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;depends_on_past&#39;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;email_on_failure&#39;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;email_on_retry&#39;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;retries&#39;</span>: <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define project, dataset, and table details</span>
</span></span><span style="display:flex;"><span>project_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;atgeir-accelerators&#39;</span>
</span></span><span style="display:flex;"><span>dataset_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;staging_dataset&#39;</span>
</span></span><span style="display:flex;"><span>transform_dataset_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;transform_dataset&#39;</span>
</span></span><span style="display:flex;"><span>reporting_dataset_id <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;reporting_dataset&#39;</span>
</span></span><span style="display:flex;"><span>source_table <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>project_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>dataset_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.global_data&#39;</span>
</span></span><span style="display:flex;"><span>countries <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;USA&#39;</span>, <span style="color:#e6db74">&#39;India&#39;</span>, <span style="color:#e6db74">&#39;Germany&#39;</span>, <span style="color:#e6db74">&#39;Japan&#39;</span>, <span style="color:#e6db74">&#39;France&#39;</span>, <span style="color:#e6db74">&#39;Canada&#39;</span>, <span style="color:#e6db74">&#39;Italy&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># DAG definition</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> DAG(
</span></span><span style="display:flex;"><span>    dag_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;load_and_transform_view&#39;</span>,
</span></span><span style="display:flex;"><span>    default_args<span style="color:#f92672">=</span>default_args,
</span></span><span style="display:flex;"><span>    description<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Load a CSV file from GCS to BigQuery and create country-specific tables&#39;</span>,
</span></span><span style="display:flex;"><span>    schedule_interval<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,  <span style="color:#75715e"># Manual trigger</span>
</span></span><span style="display:flex;"><span>    start_date<span style="color:#f92672">=</span>datetime(<span style="color:#ae81ff">2024</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>    catchup<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    tags<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;bigquery&#39;</span>, <span style="color:#e6db74">&#39;gcs&#39;</span>, <span style="color:#e6db74">&#39;csv&#39;</span>],
</span></span><span style="display:flex;"><span>) <span style="color:#66d9ef">as</span> dag:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Task 1: Check if the file exists in GCS</span>
</span></span><span style="display:flex;"><span>    check_file_exists <span style="color:#f92672">=</span> GCSObjectExistenceSensor(
</span></span><span style="display:flex;"><span>        task_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;check_file_exists&#39;</span>,
</span></span><span style="display:flex;"><span>        bucket<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bkt-src-global-data&#39;</span>,
</span></span><span style="display:flex;"><span>        object<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;global_health_data.csv&#39;</span>,
</span></span><span style="display:flex;"><span>        timeout<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>,
</span></span><span style="display:flex;"><span>        poke_interval<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>,
</span></span><span style="display:flex;"><span>        mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;poke&#39;</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Task 2: Load CSV from GCS to BigQuery</span>
</span></span><span style="display:flex;"><span>    load_csv_to_bigquery <span style="color:#f92672">=</span> GCSToBigQueryOperator(
</span></span><span style="display:flex;"><span>        task_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;load_csv_to_bq&#39;</span>,
</span></span><span style="display:flex;"><span>        bucket<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bkt-src-global-data&#39;</span>,
</span></span><span style="display:flex;"><span>        source_objects<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;global_health_data.csv&#39;</span>],
</span></span><span style="display:flex;"><span>        destination_project_dataset_table<span style="color:#f92672">=</span>source_table,
</span></span><span style="display:flex;"><span>        source_format<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;CSV&#39;</span>,
</span></span><span style="display:flex;"><span>        allow_jagged_rows<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        ignore_unknown_values<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        write_disposition<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;WRITE_TRUNCATE&#39;</span>,
</span></span><span style="display:flex;"><span>        skip_leading_rows<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>        field_delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>,
</span></span><span style="display:flex;"><span>        autodetect<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Tasks 3: Create country-specific tables and views</span>
</span></span><span style="display:flex;"><span>    create_table_tasks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    create_view_tasks <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> country <span style="color:#f92672">in</span> countries:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Create country-specific table</span>
</span></span><span style="display:flex;"><span>        create_table_task <span style="color:#f92672">=</span> BigQueryInsertJobOperator(
</span></span><span style="display:flex;"><span>            task_id<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;create_table_</span><span style="color:#e6db74">{</span>country<span style="color:#f92672">.</span>lower()<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>,
</span></span><span style="display:flex;"><span>            configuration<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;query&#34;</span>: {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;query&#34;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        CREATE OR REPLACE TABLE `</span><span style="color:#e6db74">{</span>project_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>transform_dataset_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>country<span style="color:#f92672">.</span>lower()<span style="color:#e6db74">}</span><span style="color:#e6db74">_table` AS
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        SELECT *
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        FROM `</span><span style="color:#e6db74">{</span>source_table<span style="color:#e6db74">}</span><span style="color:#e6db74">`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        WHERE country = &#39;</span><span style="color:#e6db74">{</span>country<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;useLegacySql&#34;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Create reporting view with cleaned column names</span>
</span></span><span style="display:flex;"><span>        create_view_task <span style="color:#f92672">=</span> BigQueryInsertJobOperator(
</span></span><span style="display:flex;"><span>            task_id<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;create_view_</span><span style="color:#e6db74">{</span>country<span style="color:#f92672">.</span>lower()<span style="color:#e6db74">}</span><span style="color:#e6db74">_table&#39;</span>,
</span></span><span style="display:flex;"><span>            configuration<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;query&#34;</span>: {
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;query&#34;</span>: <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        CREATE OR REPLACE VIEW `</span><span style="color:#e6db74">{</span>project_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>reporting_dataset_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>country<span style="color:#f92672">.</span>lower()<span style="color:#e6db74">}</span><span style="color:#e6db74">_view` AS
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        SELECT 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            `Year` AS `year`, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            `Disease Name` AS `disease_name`, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            `Disease Category` AS `disease_category`, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            `Prevalence Rate` AS `prevalence_rate`, 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                            `Incidence Rate` AS `incidence_rate`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        FROM `</span><span style="color:#e6db74">{</span>project_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>transform_dataset_id<span style="color:#e6db74">}</span><span style="color:#e6db74">.</span><span style="color:#e6db74">{</span>country<span style="color:#f92672">.</span>lower()<span style="color:#e6db74">}</span><span style="color:#e6db74">_table`
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                        WHERE `Availability of Vaccines Treatment` = False
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">                    &#34;&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;useLegacySql&#34;</span>: <span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Set task dependencies</span>
</span></span><span style="display:flex;"><span>        create_table_task<span style="color:#f92672">.</span>set_upstream(load_csv_to_bigquery)
</span></span><span style="display:flex;"><span>        create_view_task<span style="color:#f92672">.</span>set_upstream(create_table_task)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        create_table_tasks<span style="color:#f92672">.</span>append(create_table_task)
</span></span><span style="display:flex;"><span>        create_view_tasks<span style="color:#f92672">.</span>append(create_view_task)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Success task</span>
</span></span><span style="display:flex;"><span>    success_task <span style="color:#f92672">=</span> DummyOperator(task_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;success_task&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Define final dependencies</span>
</span></span><span style="display:flex;"><span>    check_file_exists <span style="color:#f92672">&gt;&gt;</span> load_csv_to_bigquery
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> create_table_task, create_view_task <span style="color:#f92672">in</span> zip(create_table_tasks, create_view_tasks):
</span></span><span style="display:flex;"><span>        create_table_task <span style="color:#f92672">&gt;&gt;</span> create_view_task <span style="color:#f92672">&gt;&gt;</span> success_task
</span></span></code></pre></div><hr>
<h2 id="-key-building-blocks-and-why-they-matter">üß© Key Building Blocks (And Why They Matter)</h2>
<h3 id="1-file-validation-with-gcs-sensor">1. <strong>File Validation with GCS Sensor</strong></h3>
<blockquote>
<p><strong>Pro Tip:</strong> Always check if your source file exists before you start processing. It&rsquo;ll save you hours of debugging!</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>check_file_exists <span style="color:#f92672">=</span> GCSObjectExistenceSensor(
</span></span><span style="display:flex;"><span>    task_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;check_file_exists&#39;</span>,
</span></span><span style="display:flex;"><span>    bucket<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;bkt-src-global-data&#39;</span>,
</span></span><span style="display:flex;"><span>    object<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;global_health_data.csv&#39;</span>,
</span></span><span style="display:flex;"><span>    timeout<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>,
</span></span><span style="display:flex;"><span>    poke_interval<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>,
</span></span><span style="display:flex;"><span>    mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;poke&#39;</span>,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>This sensor ensures the source file exists before proceeding, preventing downstream failures.</p>
<h3 id="2-automated-schema-detection">2. <strong>Automated Schema Detection</strong></h3>
<blockquote>
<p><strong>Why I love this:</strong> With <code>autodetect=True</code>, BigQuery figures out the schema for you. No more manually defining 50+ columns!</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>load_csv_to_bigquery <span style="color:#f92672">=</span> GCSToBigQueryOperator(
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># ... other parameters ...</span>
</span></span><span style="display:flex;"><span>    autodetect<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,  <span style="color:#75715e"># Automatically detect schema</span>
</span></span><span style="display:flex;"><span>    skip_leading_rows<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,  <span style="color:#75715e"># Skip CSV header</span>
</span></span><span style="display:flex;"><span>    allow_jagged_rows<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,  <span style="color:#75715e"># Handle inconsistent row lengths</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="3-dynamic-task-generation">3. <strong>Dynamic Task Generation</strong></h3>
<blockquote>
<p><strong>Scalability win:</strong> Want to add Brazil? Just add it to the <code>countries</code> list. The pipeline scales itself.</p></blockquote>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> country <span style="color:#f92672">in</span> countries:
</span></span><span style="display:flex;"><span>    create_table_task <span style="color:#f92672">=</span> BigQueryInsertJobOperator(<span style="color:#f92672">...</span>)
</span></span><span style="display:flex;"><span>    create_view_task <span style="color:#f92672">=</span> BigQueryInsertJobOperator(<span style="color:#f92672">...</span>)
</span></span></code></pre></div><hr>
<h2 id="-data-flow-see-it-in-action">üîÑ Data Flow: See It in Action</h2>
<div class="mermaid">

graph TD
    A[GCS Bucket: global_health_data.csv] --> B[BigQuery Staging: staging_dataset.global_data]
    B --> C[Country Tables: transform_dataset.COUNTRY_table]
    C --> D[Reporting Views: reporting_dataset.COUNTRY_view]

</div> 
<hr>
<h2 id="-configuration-highlights">‚öôÔ∏è Configuration Highlights</h2>
<h3 id="multi-dataset-architecture">Multi-Dataset Architecture</h3>
<ul>
<li><strong>staging_dataset</strong>: Raw data from GCS</li>
<li><strong>transform_dataset</strong>: Country-specific filtered tables</li>
<li><strong>reporting_dataset</strong>: Clean views for end users</li>
</ul>
<h3 id="error-handling">Error Handling</h3>
<ul>
<li>File existence validation before processing</li>
<li><code>allow_jagged_rows=True</code> for handling inconsistent CSV data</li>
<li><code>ignore_unknown_values=True</code> for data quality resilience</li>
</ul>
<h3 id="performance-optimizations">Performance Optimizations</h3>
<ul>
<li><code>WRITE_TRUNCATE</code> for efficient full refreshes</li>
<li>Parallel execution of country-specific transformations</li>
<li>Standard SQL for better performance than Legacy SQL</li>
</ul>
<hr>
<h2 id="-what-makes-this-pipeline-special">üèÜ What Makes This Pipeline Special?</h2>
<blockquote>
<p><strong>Battle-tested:</strong> These aren&rsquo;t just best practices‚Äîthey&rsquo;re solutions I&rsquo;ve used in production, under real pressure.</p></blockquote>
<h3 id="1-robust-file-handling">1. <strong>Robust File Handling</strong></h3>
<p>The <code>GCSObjectExistenceSensor</code> is a game-changer. Instead of blindly trying to process files, we verify they exist first. This prevents cascade failures and provides clear error messages when source data is missing.</p>
<h3 id="2-dynamic-task-generation">2. <strong>Dynamic Task Generation</strong></h3>
<p>Rather than hardcoding tasks for each country, the DAG dynamically generates them. Want to add Brazil to your analysis? Just add it to the <code>countries</code> list. The pipeline scales automatically.</p>
<h3 id="3-three-layer-data-architecture">3. <strong>Three-Layer Data Architecture</strong></h3>
<div class="mermaid">

graph TD
    A[staging_dataset üìÅ] -->|Raw data landing zone| B[transform_dataset üìÅ]
    B -->|Business logic applied| C[reporting_dataset üìÅ]
    C -->|Clean, user-friendly views| D[End Users üë•]

</div> 
<blockquote>
<p><strong>Why it matters:</strong> This separation of concerns makes debugging easier and provides clear data lineage.</p></blockquote>
<h3 id="4-column-renaming-magic">4. <strong>Column Renaming Magic</strong></h3>
<p>The reporting views transform ugly column names like <code>Disease Name</code> into clean, snake_case versions like <code>disease_name</code>. Your analysts will thank you.</p>
<hr>
<h2 id="-pipeline-monitoring-dashboard">üìä Pipeline Monitoring Dashboard</h2>
<p>When you run this DAG, you&rsquo;ll see something like this in the Airflow UI:</p>
<div class="mermaid">

graph TD
    A[‚úÖ check_file_exists] --> B[‚úÖ load_csv_to_bq]
    B --> C1[‚úÖ create_table_usa]
    C1 --> D1[‚úÖ create_view_usa_table]

    B --> C2[‚úÖ create_table_india]
    C2 --> D2[‚úÖ create_view_india_table]

    B --> C3[‚úÖ create_table_germany]
    C3 --> D3[‚úÖ create_view_germany_table]

    %% Add more countries similarly if needed
    B --> Cn[... More create_table_x]
    Cn --> Dn[... More create_view_x]

    D1 --> E[‚úÖ success_task]
    D2 --> E
    D3 --> E
    Dn --> E

</div> 
<hr>
<h2 id="-lessons-learned-so-you-dont-have-to">üö® Lessons Learned (So You Don&rsquo;t Have To)</h2>
<blockquote>
<p><strong>Pro Tip:</strong> Always validate your sources. The GCS sensor saved me countless hours of debugging. File missing? The pipeline stops gracefully instead of failing mysteriously downstream.</p></blockquote>
<ul>
<li><strong>Schema autodetection is your friend.</strong> With <code>autodetect=True</code>, BigQuery handles schema inference automatically. No more manually defining 50+ columns!</li>
<li><strong>Parallel processing wins.</strong> By creating country tables in parallel, what used to take 30 minutes now completes in under 5 minutes.</li>
<li><strong>Views &gt; Tables for reporting.</strong> The final reporting layer uses views instead of materialized tables. This keeps storage costs low while providing fresh data for dashboards.</li>
</ul>
<hr>
<h2 id="-real-world-applications">üåç Real-World Applications</h2>
<p>This pattern works beautifully for:</p>
<ul>
<li><strong>Multi-tenant SaaS applications</strong> (replace countries with client IDs)</li>
<li><strong>Time-series data partitioning</strong> (replace countries with date ranges)</li>
<li><strong>A/B testing pipelines</strong> (replace countries with test groups)</li>
<li><strong>Regional compliance requirements</strong> (data sovereignty by country)</li>
</ul>
<hr>
<h2 id="-whats-next">üîÆ What&rsquo;s Next?</h2>
<p>Here are some enhancements I&rsquo;m considering:</p>
<ul>
<li>Adding data quality checks with Great Expectations</li>
<li>Implementing incremental loading for large datasets</li>
<li>Adding Slack notifications for pipeline status</li>
<li>Creating automated data documentation with dbt</li>
</ul>
<hr>
<h2 id="-final-thoughts">üí≠ Final Thoughts</h2>
<p>This DAG represents more than just code‚Äîit&rsquo;s a blueprint for scalable, maintainable data pipelines. The combination of Airflow&rsquo;s orchestration capabilities with BigQuery&rsquo;s processing power creates a robust foundation for any data team.</p>
<p>The beauty lies in the details: file validation, dynamic task generation, clean data architecture, and parallel processing. These aren&rsquo;t just best practices‚Äîthey&rsquo;re battle-tested solutions that scale with your business.</p>
<hr>
<h2 id="-meet-the-author">üë§ Meet the Author</h2>
<p>Hey, I&rsquo;m Vedant! I love building data systems that just work‚Äîeven when the world is messy. If you&rsquo;re building similar pipelines or have questions about this approach, I&rsquo;d love to hear from you! Data engineering is a journey best traveled with fellow practitioners who understand the joy of a well-orchestrated pipeline and the pain of debugging a 3 AM failure.</p>
<blockquote>
<p><strong>Let&rsquo;s connect:</strong></p>
<ul>
<li><a href="https://x.com/VedantJangid2">Twitter</a></li>
<li><a href="https://github.com/vedantjangid">GitHub</a></li>
<li><a href="https://www.linkedin.com/in/vedant-jangid-0a1907204/">LinkedIn</a></li>
</ul></blockquote>

    </article>


    





    
    
    




    
    
    

<section id="articleNext" class="section nartrow">
    <h3 class="footer-next-heading">More articles from Vedant Writes</h3>
    <div class="footer-spacer"></div>
    <div class="next-articles-grid" numberOfArticles={numberOfArticles}>
        <div class="post-row">
            
                <a href="/post/blog-automation-setup/" class="article-link"
                 id="article-link-bigger">
                    <div>
                        <div class="image-container">
                            <img src="/images/hugo-github-netlify.png" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                Zero to Blog: A Lazy Engineer&#39;s Guide to Automating Web Presence
                            </h2>
                            <p class="article-excerpt">
                                A humorous yet detailed guide on building a seamless blogging workflow using Hugo, GitHub, Netlify, and GoDaddy subdomains, the lazy engineer&#39;s way.
                            </p>
                            <div class="article-metadata">
                                December 2, 2024 ¬∑ 3 min read
                            </div>
                        </div>
                    </div>
                </a>
            
                <a href="/post/from-gcs-to-bigquery-airflow-etl/" class="article-link"
                >
                    <div>
                        <div class="image-container">
                            <img src="/images/airflow-gcs-bq.png" class="article-image" />
                        </div>
                        <div>
                            <h2 class="article-title">
                                From GCS to BigQuery: Building Scalable ETL Pipelines with Apache Airflow üßë‚Äçüíª
                            </h2>
                            <p class="article-excerpt">
                                A hands-on, real-world guide to building robust, scalable ETL pipelines with Apache Airflow, GCS, and BigQuery. Learn the tricks, the pitfalls, and the magic of orchestration.
                            </p>
                            <div class="article-metadata">
                                June 27, 2025 ¬∑ 7 min read
                            </div>
                        </div>
                    </div>
                </a>
            
        </div>
    </div>
</section>

</section>


 <script src="/js/progressBar.js"></script>

        
        <div class="footer-gradient"></div>
    <div class="section narrow">
      <div class="footer-hr"></div>
      <div class="footer-container">
        <div class="footer-text">
          ¬© 2025 Vedant Writes
        </div>
        <div class="social-icon-outer">
    <div class="social-icon-container">
        
    </div>
</div>
    </div>
</div>

    </div>

    
    <script src="/js/prism.js"></script>
</body>

</html>